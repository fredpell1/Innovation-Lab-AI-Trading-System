{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')\n",
    "df = df[['Support', 'Resistance', 'Hammer', 'Williams%R', 'ZeroCross', 'SignalCross', 'Decision14','Decision28']]\n",
    "df = df.loc[df[\"Decision28\"] != -1] # we exclude the value with a decision of -1\n",
    "df = df.drop('Decision14', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_prior(df, Y):\n",
    "\n",
    "    classes = sorted(list(df[Y].unique()))\n",
    "    prior = []\n",
    "\n",
    "    for i in classes:\n",
    "        prior.append(len(df[df[Y] == i]) / len(df[Y]))\n",
    "    \n",
    "    return prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_likelihood(df, feature_name, feature_value, Y, label):\n",
    "\n",
    "    df = df[df[Y] == label]\n",
    "    mean = df[feature_name].mean()\n",
    "    std = df[feature_name].std()\n",
    "\n",
    "    p_x_given_y = len(df[df[feature_name] == feature_value]) / len(df)\n",
    "\n",
    "    return p_x_given_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(df, X, Y):\n",
    "\n",
    "    features = list(df.columns)[:-1]\n",
    "    prior = cal_prior(df, Y)\n",
    "\n",
    "    Y_pred = []\n",
    "\n",
    "    for x in X:\n",
    "        labels = sorted(list(df[Y].unique()))\n",
    "        likelihood = [1]*len(labels)\n",
    "        for i in range(len(labels)):\n",
    "            for j in range(len(features)):\n",
    "                likelihood[i] *= cal_likelihood(df, features[j], x[j], Y, labels[i])\n",
    "        \n",
    "        # Calculate posterior probability (we ignore denominator)\n",
    "        post_prob = [1]*len(labels)\n",
    "        for i in range(len(labels)):\n",
    "            post_prob[i] = likelihood[i] * prior[i]\n",
    "        \n",
    "        Y_pred.append(np.argmax(post_prob))\n",
    "\n",
    "    return np.array(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12 117]\n",
      " [  5 155]]\n",
      "0.5778546712802768\n",
      "0.5308866279069767\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.294, random_state=40, shuffle = False)\n",
    "\n",
    "X_test = test.iloc[:, :-1].values\n",
    "Y_test = test.iloc[:, -1].values\n",
    "Y_pred = naive_bayes(train, X=X_test, Y='Decision28')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred, average='micro'))\n",
    "print(balanced_accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing results with pre-built models\n",
    "### taken on https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html#sklearn.naive_bayes.CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalNB()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = CategoricalNB()\n",
    "classifier.fit(train.iloc[:,:-1].values, train.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred2 = classifier.predict(test.iloc[:, :-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12 117]\n",
      " [  5 155]]\n",
      "0.5778546712802768\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, Y_pred2))\n",
    "print(f1_score(Y_test, Y_pred2, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5778546712802768"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test.iloc[:, :-1].values,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5813148788927336\n",
      "0.5347625968992248\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(train.iloc[:,:-1].values, train.iloc[:,-1].values)\n",
    "mnb.predict(test.iloc[:, :-1].values)\n",
    "print(mnb.score(test.iloc[:, :-1].values,Y_test))\n",
    "print(balanced_accuracy_score(Y_test, mnb.predict(test.iloc[:, :-1].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.532871972318339\n",
      "0.5646075581395349\n"
     ]
    }
   ],
   "source": [
    "cnb = ComplementNB()\n",
    "cnb.fit(train.iloc[:,:-1].values, train.iloc[:,-1].values)\n",
    "cnb.predict(test.iloc[:, :-1].values)\n",
    "print(cnb.score(test.iloc[:, :-1].values,Y_test))\n",
    "print(balanced_accuracy_score(Y_test, cnb.predict(test.iloc[:, :-1].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mnb.predict(test.iloc[:, :-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111  18]\n",
      " [117  43]]\n"
     ]
    }
   ],
   "source": [
    "pred2 = cnb.predict(test.iloc[:, :-1].values)\n",
    "print(confusion_matrix(Y_test,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 13 116]\n",
      " [  5 155]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    434\n",
       "0    258\n",
       "Name: Decision28, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Decision28'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    160\n",
       "0    129\n",
       "Name: Decision28, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Decision28'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that the buy/sell ratio is not equivalent between the testing data and the training data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66873b38267121c909ae48d605043bdfcf9d13414495bb5314f1e53a9cb2aa05"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
