{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1042 entries, 0 to 1041\n",
      "Data columns (total 24 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Date         1042 non-null   object \n",
      " 1   Close        1042 non-null   float64\n",
      " 2   Var. (%)     1042 non-null   object \n",
      " 3   Open         1042 non-null   float64\n",
      " 4   Low          1042 non-null   float64\n",
      " 5   High         1042 non-null   float64\n",
      " 6   Volume       1042 non-null   object \n",
      " 7   Support      1042 non-null   int64  \n",
      " 8   Resistance   1042 non-null   int64  \n",
      " 9   Hammer       1042 non-null   float64\n",
      " 10  WilliamR     1042 non-null   float64\n",
      " 11  Williams%R   1042 non-null   int64  \n",
      " 12  12EMA        1042 non-null   float64\n",
      " 13  26 EMA       1042 non-null   float64\n",
      " 14  MACD LINE    1042 non-null   float64\n",
      " 15  SIGNAL LINE  1042 non-null   float64\n",
      " 16  HISTOGRAM    1042 non-null   float64\n",
      " 17  ZeroCross    1009 non-null   float64\n",
      " 18  SignalCross  1009 non-null   float64\n",
      " 19  Decision14   1042 non-null   int64  \n",
      " 20  Decision28   1042 non-null   int64  \n",
      " 21  Decision10   1042 non-null   int64  \n",
      " 22  Decision50   1042 non-null   int64  \n",
      " 23  Decision5    1042 non-null   int64  \n",
      "dtypes: float64(13), int64(8), object(3)\n",
      "memory usage: 195.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix of Decision14 is:\n",
      "[[  0 137]\n",
      " [  3 153]]\n",
      "\n",
      "The f1 score of Decision14 is:\n",
      "0.5221843003412969\n",
      "\n",
      "The balanced accuracy score of Decision14 is:\n",
      "0.49038461538461536\n",
      "---------------------------------------\n",
      "The confusion matrix of Decision28 is:\n",
      "[[ 12 117]\n",
      " [  5 155]]\n",
      "\n",
      "The f1 score of Decision28 is:\n",
      "0.5778546712802768\n",
      "\n",
      "The balanced accuracy score of Decision28 is:\n",
      "0.5308866279069767\n",
      "---------------------------------------\n",
      "The confusion matrix of Decision10 is:\n",
      "[[ 17 129]\n",
      " [  9 139]]\n",
      "\n",
      "The f1 score of Decision10 is:\n",
      "0.5306122448979592\n",
      "\n",
      "The balanced accuracy score of Decision10 is:\n",
      "0.5278137726767863\n",
      "---------------------------------------\n",
      "The confusion matrix of Decision50 is:\n",
      "[[ 12  93]\n",
      " [  4 173]]\n",
      "\n",
      "The f1 score of Decision50 is:\n",
      "0.6560283687943262\n",
      "\n",
      "The balanced accuracy score of Decision50 is:\n",
      "0.5458434221146086\n",
      "---------------------------------------\n",
      "The confusion matrix of Decision5 is:\n",
      "[[ 19 114]\n",
      " [  8 155]]\n",
      "\n",
      "The f1 score of Decision5 is:\n",
      "0.5878378378378378\n",
      "\n",
      "The balanced accuracy score of Decision5 is:\n",
      "0.5468886941279579\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Y_list = ['Decision14', 'Decision28', 'Decision10', 'Decision50', 'Decision5']\n",
    "\n",
    "for y in Y_list:\n",
    "    df_temp = df[['Support', 'Resistance', 'Hammer', 'ZeroCross','SignalCross', y]]\n",
    "    df_temp = df_temp.loc[df_temp[y] != -1] # we exclude the value with a decision of -1\n",
    "\n",
    "    def cal_prior(df, Y):\n",
    "\n",
    "        classes = sorted(list(df[Y].unique()))\n",
    "        prior = []\n",
    "\n",
    "        for i in classes:\n",
    "            prior.append(len(df[df[Y] == i]) / len(df[Y]))\n",
    "        \n",
    "        return prior\n",
    "\n",
    "    def cal_likelihood(df, feature_name, feature_value, Y, label):\n",
    "\n",
    "        df = df[df[Y] == label]\n",
    "        mean = df[feature_name].mean()\n",
    "        std = df[feature_name].std()\n",
    "\n",
    "        p_x_given_y = len(df[df[feature_name] == feature_value]) / len(df)\n",
    "\n",
    "        return p_x_given_y    \n",
    "\n",
    "    def naive_bayes(df, X, Y):\n",
    "\n",
    "        features = list(df.columns)[:-1]\n",
    "        prior = cal_prior(df, Y)\n",
    "\n",
    "        Y_pred = []\n",
    "\n",
    "        for x in X:\n",
    "            labels = sorted(list(df[Y].unique()))\n",
    "            likelihood = [1]*len(labels)\n",
    "            for i in range(len(labels)):\n",
    "                for j in range(len(features)):\n",
    "                    likelihood[i] *= cal_likelihood(df, features[j], x[j], Y, labels[i])\n",
    "            \n",
    "            # Calculate posterior probability (we ignore denominator)\n",
    "            post_prob = [1]*len(labels)\n",
    "            for i in range(len(labels)):\n",
    "                post_prob[i] = likelihood[i] * prior[i]\n",
    "            \n",
    "            Y_pred.append(np.argmax(post_prob))\n",
    "\n",
    "        return np.array(Y_pred)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train, test = train_test_split(df_temp, test_size=0.294, random_state=40, shuffle = False)\n",
    "\n",
    "    X_test = test.iloc[:, :-1].values\n",
    "    Y_test = test.iloc[:, -1].values\n",
    "    Y_pred = naive_bayes(train, X=X_test, Y=y)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "    print(f'The confusion matrix of {y} is:\\n{confusion_matrix(Y_test, Y_pred)}')\n",
    "    print(f'\\nThe f1 score of {y} is:\\n{f1_score(Y_test, Y_pred, average=\"micro\")}')\n",
    "    print(f'\\nThe balanced accuracy score of {y} is:\\n{balanced_accuracy_score(Y_test, Y_pred)}')\n",
    "    print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Decision5 has the highest balanced accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.321311475409836"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the buy/sell ratio of the training dataset from Decision5\n",
    "ratio = len(train[train.iloc[:,-1] == 1]) / len(train[train.iloc[:,-1] == 0])\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2255639097744362"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the buy/sell ratio of the testing dataset from Decision5\n",
    "ratio = len(test[test.iloc[:,-1] == 1]) / len(test[test.iloc[:,-1] == 0])\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that the buy/sell ratio is not equivalent between the testing data and the training data thus we will use\n",
    "# a slightly different naive bayes classifier called complement naive bayes that corrects the imbalances"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1500c23fa3da933eb48763b18a00243dbdcd69daa062c1b39b77a14cf22f605c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
